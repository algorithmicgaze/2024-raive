<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Interactive ONNX Web Runtime Inference</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <style>
      html,
      body {
        font-family: system-ui, -apple-system, "Segoe UI", Roboto, sans-serif;
        font-size: 18px;
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      canvas {
        border: 1px solid #aaa;
      }

      .side-by-side {
        display: flex;
        gap: 1rem;
      }

      .popup-wrapper {
        position: fixed;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        background-color: rgba(0, 0, 0, 0.5);
      }

      .popup {
        position: absolute;
        top: 300px;
        left: 50%;
        transform: translate(-50%, -50%);
        padding: 1rem;
        background-color: rgba(0, 0, 0, 0.8);
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.1);
        z-index: 1000;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
      }
    </style>
  </head>

  <body>
    <h1>Interactive ONNX Web Runtime Inference</h1>
    <div class="side-by-side">
      <canvas id="inputCanvas" width="512" height="512"></canvas>
      <canvas id="outputCanvas" width="512" height="512"></canvas>
    </div>
    <br />
    <div class="controls">
      <button onclick="clearCanvas()">Clear Canvas</button>
      <button onclick="runInference()">Run Inference</button>
      <label><input type="checkbox" name="realtime" id="realtime" checked /> Real-time inference</label>
    </div>
    <br />
    <div class="popup-wrapper">
      <div class="popup">Loading model (207MB)...</div>
    </div>

    <script>
      let session, device;
      let isRunning = false;
      const inputCanvas = document.getElementById("inputCanvas");
      const ctx = inputCanvas.getContext("2d", { willReadFrequently: true });
      const outputCanvas = document.getElementById("outputCanvas");
      const outputCtx = outputCanvas.getContext("2d");
      clearCanvas();

      // Load the control image and draw it on the canvas
      const img = new Image();
      img.onload = () => {
        ctx.drawImage(img, 0, 0);
      };
      img.src = "trees_control.png";

      let isDrawing = false;
      const BUFFER_SIZE = 512 * 512 * 3 * 4;
      let inputArray = new Float32Array(3 * 512 * 512);
      let outputArray = new Float32Array(3 * 512 * 512);
      let inputBuffer;
      let outputBuffer;
      let stagingBuffer;
      let inputTensor, outputTensor;

      async function loadModel() {
        try {
          session = await ort.InferenceSession.create("generator_epoch_20.onnx", {
            enableGraphCapture: true,
            executionProviders: ["webgpu"],
          });
          console.log("Model loaded successfully");
          device = ort.env.webgpu.device;

          inputBuffer = device.createBuffer({
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            size: BUFFER_SIZE,
          });
          outputBuffer = device.createBuffer({
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
            size: BUFFER_SIZE,
          });
          stagingBuffer = device.createBuffer({
            usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            size: BUFFER_SIZE,
          });
          inputTensor = ort.Tensor.fromGpuBuffer(inputBuffer, { dataType: "float32", dims: [1, 3, 512, 512] });
          outputTensor = ort.Tensor.fromGpuBuffer(outputBuffer, { dataType: "float32", dims: [1, 3, 512, 512] });
          window.session = session;

          document.querySelector(".popup-wrapper").style.display = "none";
        } catch (e) {
          console.error("Failed to load the model:", e);
          document.querySelector(".popup").textContent = "Failed to load the model: " + e;
        }
      }

      function clearCanvas() {
        ctx.fillStyle = "white";
        ctx.fillRect(0, 0, inputCanvas.width, inputCanvas.height);
      }

      inputCanvas.addEventListener("mousedown", startDrawing);
      inputCanvas.addEventListener("mousemove", draw);
      inputCanvas.addEventListener("mouseup", stopDrawing);
      inputCanvas.addEventListener("mouseout", stopDrawing);

      function startDrawing(e) {
        isDrawing = true;
        draw(e);
      }

      function draw(e) {
        if (!isDrawing) return;
        ctx.lineWidth = 3;
        ctx.lineCap = "round";
        ctx.strokeStyle = "black";

        ctx.lineTo(e.clientX - inputCanvas.offsetLeft, e.clientY - inputCanvas.offsetTop);
        ctx.stroke();
        ctx.beginPath();
        ctx.moveTo(e.clientX - inputCanvas.offsetLeft, e.clientY - inputCanvas.offsetTop);
        if (document.getElementById("realtime").checked) {
          runInference();
        }
      }

      function stopDrawing() {
        isDrawing = false;
        ctx.beginPath();
      }

      function calcStats(prefix, buffer) {
        let min = buffer[0];
        let max = buffer[0];
        let sum = 0;

        for (let i = 0; i < buffer.length; i++) {
          const value = buffer[i];
          min = Math.min(min, value);
          max = Math.max(max, value);
          sum += value;
        }

        const mean = sum / buffer.length;
        console.log(prefix, "Min:", min, "Max:", max, "Mean:", mean);
      }

      function clamp(v) {
        return Math.max(0, Math.min(255, Math.round(v)));
      }

      async function runInference() {
        if (isRunning) return;
        isRunning = true;
        const startTime = performance.now();

        const imageData = ctx.getImageData(0, 0, inputCanvas.width, inputCanvas.height);
        const pixelCount = 512 * 512;
        // calcStats("Canvas data", imageData.data);

        // ONNX expects images in NCHW format, so we need to have all channels after each other.
        // In other words, first all red pixels, then all green pixels, and finally all blue pixels.
        let redOffset = 0;
        let greenOffset = pixelCount;
        let blueOffset = pixelCount * 2;
        for (let i = 0; i < pixelCount; i++) {
          const inOffset = i * 4;
          inputArray[redOffset++] = imageData.data[inOffset] / 127.5 - 1;
          inputArray[greenOffset++] = imageData.data[inOffset + 1] / 127.5 - 1;
          inputArray[blueOffset++] = imageData.data[inOffset + 2] / 127.5 - 1;
        }
        // calcStats("Input tensor", inputArray);
        device.queue.writeBuffer(inputBuffer, 0, inputArray);

        // Run inference
        await session.run({ input: inputTensor }, { output: outputTensor });

        // Copy the output tensor to the staging buffer
        const commandEncoder = device.createCommandEncoder();
        commandEncoder.copyBufferToBuffer(outputBuffer, 0, stagingBuffer, 0, BUFFER_SIZE);
        device.queue.submit([commandEncoder.finish()]);

        await stagingBuffer.mapAsync(GPUMapMode.READ, 0, BUFFER_SIZE);
        const copyArrayBuffer = stagingBuffer.getMappedRange(0, BUFFER_SIZE);
        outputArray.set(new Float32Array(copyArrayBuffer));
        stagingBuffer.unmap();

        // Convert output to image
        // We're reusing the same imageData object to avoid creating a new one every time
        // Assuming outputData is in NCHW format
        redOffset = 0;
        greenOffset = pixelCount;
        blueOffset = pixelCount * 2;
        for (let i = 0; i < pixelCount; i++) {
          const outOffset = i * 4;
          imageData.data[outOffset] = clamp(outputArray[redOffset++] * 127.5 + 127.5);
          imageData.data[outOffset + 1] = clamp(outputArray[greenOffset++] * 127.5 + 127.5);
          imageData.data[outOffset + 2] = clamp(outputArray[blueOffset++] * 127.5 + 127.5);
          imageData.data[outOffset + 3] = 255;
        }

        outputCtx.putImageData(imageData, 0, 0);
        isRunning = false;
        const endTime = performance.now();
        console.log(`Total inference time: ${endTime - startTime} ms`);
      }

      // Load the model when the page loads
      loadModel();
    </script>
  </body>
</html>
